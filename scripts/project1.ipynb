{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[138.47 ,  51.655,  97.827, ...,   1.24 ,  -2.475, 113.497],\n",
       "       [160.937,  68.768, 103.235, ...,   0.   ,   0.   ,  46.226],\n",
       "       [  0.   , 162.172, 125.953, ...,   0.   ,   0.   ,  44.251],\n",
       "       ...,\n",
       "       [105.457,  60.526,  75.839, ...,   0.   ,   0.   ,  41.992],\n",
       "       [ 94.951,  19.362,  68.812, ...,   0.   ,   0.   ,   0.   ],\n",
       "       [  0.   ,  72.756,  70.831, ...,   0.   ,   0.   ,   0.   ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX = np.where(tX==-999, 0, tX)\n",
    "tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.23787741e+251  4.66890739e+250  8.88960134e+250  1.04096961e+251\n",
      "  1.70573873e+249  3.20795143e+251 -1.03683380e+249  2.28422123e+249\n",
      "  2.68495925e+250  2.60163252e+251  1.57891643e+249  3.18680444e+248\n",
      "  3.13472510e+248  4.91092550e+250 -9.40941505e+246 -2.33678042e+246\n",
      "  5.63554614e+250 -1.12919545e+247  4.13028665e+247  5.83370652e+250\n",
      " -1.39758106e+246  3.18436637e+251  1.69200112e+249  9.98061967e+250\n",
      " -3.11081800e+246 -7.29342575e+246  4.04565569e+250 -8.40971505e+246\n",
      " -4.40164414e+246  1.54698537e+251] inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lamol_000\\Documents\\EPFL\\MA1\\Machine Learning\\EPFL-Machine-Learning-Higgs-2019\\scripts\\costs.py:14: RuntimeWarning: overflow encountered in matmul\n",
      "  return e.T@e / (2 * len(y))\n"
     ]
    }
   ],
   "source": [
    "from implementations import *\n",
    "\n",
    "initial_w = np.zeros(len(tX[0]))\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "weigths, loss = least_squares_GD(y, tX, initial_w, max_iters, gamma)\n",
    "\n",
    "print(weigths, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX = standardize_matrix(tX)\n",
    "len(tX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.22443381,  0.19387987,  0.74197336, ..., -0.40458096,\n",
       "        -0.44868057,  0.92798707],\n",
       "       [ 1.4911326 ,  0.39702299,  0.80617005, ..., -0.41930061,\n",
       "        -0.41930061,  0.1294339 ],\n",
       "       [-0.41930061,  1.5057929 ,  1.07584839, ..., -0.41930061,\n",
       "        -0.41930061,  0.10598928],\n",
       "       ...,\n",
       "       [ 0.83254673,  0.29918476,  0.48096063, ..., -0.41930061,\n",
       "        -0.41930061,  0.0791734 ],\n",
       "       [ 0.70783326, -0.18946032,  0.3975453 , ..., -0.41930061,\n",
       "        -0.41930061, -0.41930061],\n",
       "       [-0.41930061,  0.4443633 ,  0.42151222, ..., -0.41930061,\n",
       "        -0.41930061, -0.41930061]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cross validation for training, return the optimal weigths and theirs respective loss for the train and the test datas\n",
    "def cross_validation(y, tx, k_indices, k, lambda_):\n",
    "    \n",
    "    # get k'th subgroup in test, others in train\n",
    "    training_indices = k_indices[~(np.arange(len(k_indices)) == k)].reshape(-1)\n",
    "    test_indices = k_indices[k]\n",
    "    \n",
    "    tx_train = tx[training_indices]\n",
    "    tx_test = tx[test_indices]\n",
    "    y_train = y[training_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "    # optimization with ridge_regression\n",
    "    weigths = ridge_regression(y_train, tx_train, lambda_)\n",
    "    \n",
    "    # compute the loss for the train and test datas with the weigths found\n",
    "    loss_train = compute_mse(y_train, tx_train, weigths)\n",
    "    loss_test = compute_mse(y_test, tx_test, weigths)\n",
    "    \n",
    "    return weigths, loss_train, loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the best hyperparameters for regularized optimization\n",
    "def best_hyperparameters(y, tx, lambdas, k_fold, seed=1):\n",
    "    # for each lambda, store the respective loss and weigths\n",
    "    losses = []\n",
    "    weigths_all = []\n",
    "    \n",
    "    # build k indices for k-fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    \n",
    "    # compute cross validation for each lambda\n",
    "    for lambda_ in lambdas:\n",
    "        \n",
    "        # to compute the total loss of each lambda, compute the loss for each iteration of the k-fold and compute the mean\n",
    "        losses_test_tmp = []\n",
    "        \n",
    "        # compute loss for each iteration of the k_fold\n",
    "        for k in range(k_fold):\n",
    "            weigths, loss_train, loss_test = cross_validation(y, tx, k_indices, k, lambda_)\n",
    "            losses_test_tmp.append(loss_test)\n",
    "            weigths_all.append(weigths)\n",
    "            \n",
    "            \n",
    "        #compute the loss for the specific lambda by taking the mean of the losses of each iteration of the k-fold\n",
    "        losses.append(np.mean(losses_test_tmp))\n",
    "        \n",
    "    # find the optimal hyperparameter lambda by getting the minimum loss\n",
    "    best_lambda_index = np.argmin(losses)\n",
    "    optimal_lambda = lambdas[best_lambda_index]\n",
    "    optimal_weigths = weigths_all[best_lambda_index]\n",
    "    minimum_loss = losses[best_lambda_index]\n",
    "    \n",
    "    return optimal_lambda, optimal_weigths, minimum_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, weights, _ = best_hyperparameters(y, tX, np.logspace(-4,0), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for testing the predictor, modify the tx_test\n",
    "\n",
    "tX_test = np.where(tX_test==-999, np.NaN, tX_test)\n",
    "tX_test = tX_test[~np.isnan(tX_test).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/sample-submission_test.csv' \n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
